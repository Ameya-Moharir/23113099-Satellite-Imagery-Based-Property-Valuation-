{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training (Alternative Workflow)\n",
    "## Enrollment: 23113099\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ NOTE: This notebook is not used in the primary workflow\n",
    "\n",
    "\n",
    "## Primary Implementation\n",
    "\n",
    "All model training and evaluation are contained in:\n",
    "**→ `PropertyValuation_SatelliteImagery_23113099.ipynb`**\n",
    "\n",
    "This single notebook includes:\n",
    "- ✅ Baseline XGBoost training\n",
    "- ✅ Neural network fusion training\n",
    "- ✅ Enhanced XGBoost training (tabular + images)\n",
    "- ✅ Grad-CAM explainability\n",
    "- ✅ Comprehensive model comparison\n",
    "- ✅ Final predictions (23113099_final.csv)\n",
    "\n",
    "---\n",
    "\n",
    "## Why This File Exists\n",
    "\n",
    "This file is included only to satisfy the recommended three-file structure mentioned in guidelines. However, following the clarification that a single notebook is acceptable, all implementation is in the ENHANCED notebook for better integration and analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## To Run the Project\n",
    "\n",
    "1. Open `PropertyValuation_SatelliteImagery_23113099.ipynb`\n",
    "2. Run all cells sequentially\n",
    "3. All results are generated, including:\n",
    "   - Baseline results\n",
    "   - Neural fusion results\n",
    "   - Enhanced XGBoost results\n",
    "   - Final predictions file\n",
    "\n",
    "**No need to run this file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enhanced datasets\n",
    "train_data = pd.read_csv('data/processed/train_enhanced.csv')\n",
    "test_data = pd.read_csv('data/processed/test_enhanced.csv')\n",
    "\n",
    "# Load metadata\n",
    "with open('outputs/preprocessing_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f'\\nTraining samples: {len(train_data):,}')\n",
    "print(f'Test samples: {len(test_data):,}')\n",
    "print(f'Total features: {metadata[\"total_features\"]}')\n",
    "print(f'  - Tabular: {metadata[\"tabular_features\"]}')\n",
    "print(f'  - Image PCA: {metadata[\"pca_components\"]}')\n",
    "\n",
    "print('\\n✓ Data loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features (tabular + PCA)\n",
    "feature_cols = [col for col in train_data.columns \n",
    "                if col not in ['id', 'date', 'price']]\n",
    "\n",
    "# Separate tabular and PCA features\n",
    "tabular_cols = [col for col in feature_cols if not col.startswith('cnn_pc')]\n",
    "pca_cols = [col for col in feature_cols if col.startswith('cnn_pc')]\n",
    "\n",
    "print(f'Feature columns:')\n",
    "print(f'  Tabular: {len(tabular_cols)}')\n",
    "print(f'  Image PCA: {len(pca_cols)}')\n",
    "print(f'  Total: {len(feature_cols)}')\n",
    "\n",
    "# Extract data\n",
    "X_all_features = train_data[feature_cols].values\n",
    "X_tabular_only = train_data[tabular_cols].values\n",
    "y_train = train_data['price'].values\n",
    "\n",
    "X_test_all = test_data[feature_cols].values\n",
    "X_test_tabular = test_data[tabular_cols].values\n",
    "test_ids = test_data['id'].values\n",
    "\n",
    "print('\\n✓ Features prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all features\n",
    "scaler_all = StandardScaler()\n",
    "X_all_scaled = scaler_all.fit_transform(X_all_features)\n",
    "X_test_all_scaled = scaler_all.transform(X_test_all)\n",
    "\n",
    "# Scale tabular only\n",
    "scaler_tabular = StandardScaler()\n",
    "X_tabular_scaled = scaler_tabular.fit_transform(X_tabular_only)\n",
    "X_test_tabular_scaled = scaler_tabular.transform(X_test_tabular)\n",
    "\n",
    "print('✓ Features scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for both feature sets\n",
    "X_train_all, X_val_all, y_train_split, y_val_split = train_test_split(\n",
    "    X_all_scaled, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_tab, X_val_tab, _, _ = train_test_split(\n",
    "    X_tabular_scaled, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Training samples: {X_train_all.shape[0]:,}')\n",
    "print(f'Validation samples: {X_val_all.shape[0]:,}')\n",
    "print('\\n✓ Data split complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline\n",
    "baseline_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print('Training baseline XGBoost...')\n",
    "baseline_model.fit(X_train_tab, y_train_split)\n",
    "\n",
    "# Evaluate\n",
    "val_pred_baseline = baseline_model.predict(X_val_tab)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_val_split, val_pred_baseline))\n",
    "baseline_r2 = r2_score(y_val_split, val_pred_baseline)\n",
    "baseline_mae = mean_absolute_error(y_val_split, val_pred_baseline)\n",
    "\n",
    "print('\\nBaseline Results:')\n",
    "print(f'  RMSE: ${baseline_rmse:,.2f}')\n",
    "print(f'  R² Score: {baseline_r2:.4f}')\n",
    "print(f'  MAE: ${baseline_mae:,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('MODEL 2: ENHANCED XGBOOST (TABULAR + IMAGE PCA)')\n",
    "print('='*70)\n",
    "\n",
    "# Train enhanced model\n",
    "enhanced_model = xgb.XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print('Training enhanced XGBoost...')\n",
    "enhanced_model.fit(X_train_all, y_train_split)\n",
    "\n",
    "# Evaluate\n",
    "val_pred_enhanced = enhanced_model.predict(X_val_all)\n",
    "enhanced_rmse = np.sqrt(mean_squared_error(y_val_split, val_pred_enhanced))\n",
    "enhanced_r2 = r2_score(y_val_split, val_pred_enhanced)\n",
    "enhanced_mae = mean_absolute_error(y_val_split, val_pred_enhanced)\n",
    "\n",
    "print('\\nEnhanced Results:')\n",
    "print(f'  RMSE: ${enhanced_rmse:,.2f}')\n",
    "print(f'  R² Score: {enhanced_r2:.4f}')\n",
    "print(f'  MAE: ${enhanced_mae:,.2f}')\n",
    "\n",
    "improvement = ((enhanced_r2 - baseline_r2) / baseline_r2) * 100\n",
    "print(f'\\nImprovement over baseline: {improvement:+.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('MODEL COMPARISON')\n",
    "print('='*70)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Baseline XGBoost (Tabular Only)', \n",
    "              'Enhanced XGBoost (Tabular + Image PCA)'],\n",
    "    'RMSE': [baseline_rmse, enhanced_rmse],\n",
    "    'R² Score': [baseline_r2, enhanced_r2],\n",
    "    'MAE': [baseline_mae, enhanced_mae]\n",
    "})\n",
    "\n",
    "print('\\n' + comparison_df.to_string(index=False))\n",
    "\n",
    "# Determine best model\n",
    "best_model_name = 'Enhanced XGBoost' if enhanced_r2 > baseline_r2 else 'Baseline XGBoost'\n",
    "best_r2 = max(baseline_r2, enhanced_r2)\n",
    "\n",
    "print(f'\\n{\"=\"*70}')\n",
    "print(f'BEST MODEL: {best_model_name}')\n",
    "print(f'R² Score: {best_r2:.4f}')\n",
    "print(f'{\"=\"*70}')\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('outputs/model_comparison_alternative.csv', index=False)\n",
    "print('\\n✓ Comparison saved to outputs/model_comparison_alternative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('CREATING VISUALIZATIONS')\n",
    "print('='*70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# R² Comparison\n",
    "models = ['Baseline\\n(Tabular)', 'Enhanced\\n(Tab+Img PCA)']\n",
    "r2_scores = [baseline_r2, enhanced_r2]\n",
    "colors = ['steelblue', 'green']\n",
    "\n",
    "bars = axes[0].bar(range(2), r2_scores, color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[0].set_xticks(range(2))\n",
    "axes[0].set_xticklabels(models)\n",
    "axes[0].set_ylabel('R² Score')\n",
    "axes[0].set_title('Model Comparison: R² Score')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, score in zip(bars, r2_scores):\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{score:.4f}',\n",
    "                 ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# RMSE Comparison\n",
    "rmse_scores = [baseline_rmse, enhanced_rmse]\n",
    "bars = axes[1].bar(range(2), rmse_scores, color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[1].set_xticks(range(2))\n",
    "axes[1].set_xticklabels(models)\n",
    "axes[1].set_ylabel('RMSE ($)')\n",
    "axes[1].set_title('Model Comparison: RMSE (Lower is Better)')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, score in zip(bars, rmse_scores):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'${score/1000:.0f}K',\n",
    "                 ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/model_comparison_alternative.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('✓ Visualization saved to outputs/model_comparison_alternative.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use enhanced model (best performer)\n",
    "print(f'Using: {best_model_name}')\n",
    "\n",
    "if enhanced_r2 > baseline_r2:\n",
    "    test_predictions = enhanced_model.predict(X_test_all_scaled)\n",
    "    model_used = 'Enhanced XGBoost'\n",
    "else:\n",
    "    test_predictions = baseline_model.predict(X_test_tabular_scaled)\n",
    "    model_used = 'Baseline XGBoost'\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'predicted_price': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('23113099_final_alternative.csv', index=False)\n",
    "\n",
    "print(f'\\n{\"=\"*70}')\n",
    "print('✓ PREDICTIONS COMPLETE')\n",
    "print(f'{\"=\"*70}')\n",
    "print(f'Model used: {model_used}')\n",
    "print(f'File created: 23113099_final_alternative.csv')\n",
    "print(f'Samples: {len(submission):,}')\n",
    "print(f'\\nPrediction statistics:')\n",
    "print(f'  Mean: ${test_predictions.mean():,.0f}')\n",
    "print(f'  Median: ${np.median(test_predictions):,.0f}')\n",
    "print(f'  Min: ${test_predictions.min():,.0f}')\n",
    "print(f'  Max: ${test_predictions.max():,.0f}')\n",
    "\n",
    "print('\\nFirst 5 predictions:')\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nResults Summary:')\n",
    "print(f'  Baseline XGBoost: R² {baseline_r2:.4f}, RMSE ${baseline_rmse:,.0f}')\n",
    "print(f'  Enhanced XGBoost: R² {enhanced_r2:.4f}, RMSE ${enhanced_rmse:,.0f}')\n",
    "print(f'  Best Model: {best_model_name} (R² {best_r2:.4f})')\n",
    "\n",
    "print('\\nFiles Generated:')\n",
    "print('  • 23113099_final_alternative.csv (predictions)')\n",
    "print('  • outputs/model_comparison_alternative.csv')\n",
    "print('  • outputs/model_comparison_alternative.png')\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('✓ ALL TASKS COMPLETE')\n",
    "print('='*70)\n",
    "\n",
    "print('\\nNote: This alternative workflow provides baseline results.')\n",
    "print('For comprehensive analysis including:')\n",
    "print('  - Neural network fusion architecture')\n",
    "print('  - Grad-CAM visual explainability')\n",
    "print('  - Comprehensive EDA')\n",
    "print('  - Detailed feature analysis')\n",
    "print('\\nPlease use PropertyValuation_SatelliteImagery_23113099.ipynb instead.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
