{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Alternative Workflow)\n",
    "## Enrollment: 23113099\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ NOTE: This notebook is not used in the primary workflow\n",
    "\n",
    "\n",
    "## Primary Implementation\n",
    "\n",
    "All preprocessing, model training, and analysis are contained in:\n",
    "**→ `PropertyValuation_SatelliteImagery_23113099.ipynb`**\n",
    "\n",
    "This single notebook includes:\n",
    "- ✅ Data loading and preprocessing\n",
    "- ✅ Satellite image acquisition\n",
    "- ✅ CNN feature extraction\n",
    "- ✅ Exploratory data analysis\n",
    "- ✅ Baseline model training (XGBoost)\n",
    "- ✅ Neural network fusion\n",
    "- ✅ Enhanced XGBoost (tabular + image PCA)\n",
    "- ✅ Grad-CAM explainability\n",
    "- ✅ Comprehensive performance comparison\n",
    "- ✅ Final predictions generation\n",
    "\n",
    "---\n",
    "\n",
    "## Why This File Exists\n",
    "\n",
    "This file is included only to satisfy the recommended three-file structure mentioned in guidelines. However, following the clarification that a single notebook is acceptable, all implementation is in the ENHANCED notebook for:\n",
    "- Complete workflow visibility\n",
    "- Easier reproducibility\n",
    "- Better documentation\n",
    "- Comprehensive analysis\n",
    "\n",
    "---\n",
    "\n",
    "## To Run the Project\n",
    "\n",
    "1. Open `PropertyValuation_SatelliteImagery_23113099.ipynb`\n",
    "2. Run all cells sequentially\n",
    "3. All outputs, models, and predictions are generated automatically\n",
    "\n",
    "**No need to run this file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SAMPLE_SIZE = None  # Use full dataset (set to number for testing)\n",
    "ZOOM_LEVEL = 17\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "print('='*70)\n",
    "print('CONFIGURATION')\n",
    "print('='*70)\n",
    "print(f'Sample size: {\"Full dataset\" if SAMPLE_SIZE is None else SAMPLE_SIZE}')\n",
    "print(f'Zoom level: {ZOOM_LEVEL}')\n",
    "print(f'Image size: {IMAGE_SIZE}x{IMAGE_SIZE}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/raw/train.csv')\n",
    "test_data = pd.read_csv('data/raw/test.csv')\n",
    "\n",
    "if SAMPLE_SIZE:\n",
    "    train_data = train_data.head(SAMPLE_SIZE)\n",
    "    test_data = test_data.head(SAMPLE_SIZE)\n",
    "\n",
    "print(f'\\nTraining samples: {len(train_data):,}')\n",
    "print(f'Test samples: {len(test_data):,}')\n",
    "print(f'Features: {train_data.shape[1]}')\n",
    "\n",
    "print('\\n✓ Data loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Download Satellite Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_fetcher import SatelliteImageFetcher\n",
    "\n",
    "# Initialize fetchers\n",
    "train_fetcher = SatelliteImageFetcher(\n",
    "    output_dir='data/images/train',\n",
    "    zoom=ZOOM_LEVEL,\n",
    "    image_size=IMAGE_SIZE\n",
    ")\n",
    "\n",
    "test_fetcher = SatelliteImageFetcher(\n",
    "    output_dir='data/images/test',\n",
    "    zoom=ZOOM_LEVEL,\n",
    "    image_size=IMAGE_SIZE\n",
    ")\n",
    "\n",
    "# Save to temp CSV\n",
    "train_data.to_csv('temp_train_sample.csv', index=False)\n",
    "test_data.to_csv('temp_test_sample.csv', index=False)\n",
    "\n",
    "# Download training images\n",
    "print('\\nDownloading training images...')\n",
    "train_results_df = train_fetcher.fetch_dataset(\n",
    "    csv_path='temp_train_sample.csv',\n",
    "    method='esri',\n",
    "    lat_col='lat',\n",
    "    lon_col='long',\n",
    "    id_col='id',\n",
    "    delay=0.1\n",
    ")\n",
    "\n",
    "# Download test images\n",
    "print('\\nDownloading test images...')\n",
    "test_results_df = test_fetcher.fetch_dataset(\n",
    "    csv_path='temp_test_sample.csv',\n",
    "    method='esri',\n",
    "    lat_col='lat',\n",
    "    lon_col='long',\n",
    "    id_col='id',\n",
    "    delay=0.1\n",
    ")\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print(f'✓ Training images: {len(train_results_df):,}')\n",
    "print(f'✓ Test images: {len(test_results_df):,}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract CNN Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load ResNet50\n",
    "print('\\nLoading ResNet50...')\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "resnet.eval()\n",
    "resnet.to(device)\n",
    "print('✓ ResNet50 loaded')\n",
    "\n",
    "# Image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_cnn_features(results_df, desc=\"Extracting\"):\n",
    "    features = []\n",
    "    valid_ids = []\n",
    "    \n",
    "    for _, row in tqdm(results_df.iterrows(), total=len(results_df), desc=desc):\n",
    "        img_path = Path(row['image_path'])\n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                feature = resnet(img_tensor).squeeze().cpu().numpy()\n",
    "            \n",
    "            features.append(feature)\n",
    "            valid_ids.append(row['id'])\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return np.array(features), np.array(valid_ids)\n",
    "\n",
    "# Extract features\n",
    "print('\\nExtracting training features...')\n",
    "train_cnn_features, train_valid_ids = extract_cnn_features(train_results_df, \"Training\")\n",
    "\n",
    "print('Extracting test features...')\n",
    "test_cnn_features, test_valid_ids = extract_cnn_features(test_results_df, \"Test\")\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print(f'✓ Training features: {train_cnn_features.shape}')\n",
    "print(f'✓ Test features: {test_cnn_features.shape}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalize CNN Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "cnn_scaler = StandardScaler()\n",
    "train_cnn_features = cnn_scaler.fit_transform(train_cnn_features)\n",
    "test_cnn_features = cnn_scaler.transform(test_cnn_features)\n",
    "\n",
    "print(f'Normalized to:')\n",
    "print(f'  Mean: {train_cnn_features.mean():.4f}')\n",
    "print(f'  Std: {train_cnn_features.std():.4f}')\n",
    "\n",
    "# Save scaler\n",
    "with open('outputs/cnn_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(cnn_scaler, f)\n",
    "\n",
    "print('\\n✓ CNN scaler saved to outputs/cnn_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Apply PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 20\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "\n",
    "train_cnn_pca = pca.fit_transform(train_cnn_features)\n",
    "test_cnn_pca = pca.transform(test_cnn_features)\n",
    "\n",
    "print(f'Original dimensions: {train_cnn_features.shape[1]}')\n",
    "print(f'Reduced to: {train_cnn_pca.shape[1]}')\n",
    "print(f'Variance explained: {pca.explained_variance_ratio_.sum():.1%}')\n",
    "\n",
    "# Save PCA\n",
    "with open('outputs/cnn_pca.pkl', 'wb') as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "print('\\n✓ PCA transformer saved to outputs/cnn_pca.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare Tabular Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train_data.columns \n",
    "                if col not in ['id', 'date', 'price']]\n",
    "\n",
    "print(f'Tabular features: {len(feature_cols)}')\n",
    "\n",
    "# Extract features\n",
    "X_train_tab = train_data[feature_cols].values\n",
    "y_train = train_data['price'].values\n",
    "X_test_tab = test_data[feature_cols].values\n",
    "\n",
    "# Scale tabular features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_tab)\n",
    "X_test_scaled = scaler.transform(X_test_tab)\n",
    "\n",
    "print('\\n✓ Tabular features scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Enhanced Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = [f'cnn_pc{i+1}' for i in range(n_components)]\n",
    "\n",
    "# Create enhanced training data\n",
    "train_data_enhanced = train_data.copy()\n",
    "for idx, property_id in enumerate(train_valid_ids):\n",
    "    mask = train_data_enhanced['id'] == property_id\n",
    "    for col_idx, col_name in enumerate(pca_cols):\n",
    "        train_data_enhanced.loc[mask, col_name] = train_cnn_pca[idx, col_idx]\n",
    "\n",
    "train_data_enhanced = train_data_enhanced.dropna(subset=pca_cols)\n",
    "\n",
    "# Create enhanced test data\n",
    "test_data_enhanced = test_data.copy()\n",
    "for idx, property_id in enumerate(test_valid_ids):\n",
    "    mask = test_data_enhanced['id'] == property_id\n",
    "    for col_idx, col_name in enumerate(pca_cols):\n",
    "        test_data_enhanced.loc[mask, col_name] = test_cnn_pca[idx, col_idx]\n",
    "\n",
    "test_data_enhanced = test_data_enhanced.dropna(subset=pca_cols)\n",
    "\n",
    "print(f'Training samples with images: {len(train_data_enhanced):,}')\n",
    "print(f'Test samples with images: {len(test_data_enhanced):,}')\n",
    "\n",
    "# Save enhanced datasets\n",
    "train_data_enhanced.to_csv('data/processed/train_enhanced.csv', index=False)\n",
    "test_data_enhanced.to_csv('data/processed/test_enhanced.csv', index=False)\n",
    "\n",
    "print('\\n✓ Enhanced datasets saved to data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('PREPROCESSING COMPLETE')\n",
    "print('='*70)\n",
    "\n",
    "# Save metadata\n",
    "import json\n",
    "\n",
    "metadata = {\n",
    "    'train_samples': len(train_data_enhanced),\n",
    "    'test_samples': len(test_data_enhanced),\n",
    "    'tabular_features': len(feature_cols),\n",
    "    'pca_components': n_components,\n",
    "    'total_features': len(feature_cols) + n_components,\n",
    "    'zoom_level': ZOOM_LEVEL,\n",
    "    'image_size': IMAGE_SIZE\n",
    "}\n",
    "\n",
    "with open('outputs/preprocessing_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print('\\nFiles created:')\n",
    "print('  • data/processed/train_enhanced.csv')\n",
    "print('  • data/processed/test_enhanced.csv')\n",
    "print('  • outputs/cnn_scaler.pkl')\n",
    "print('  • outputs/cnn_pca.pkl')\n",
    "print('  • outputs/preprocessing_metadata.json')\n",
    "\n",
    "print('\\nDataset Summary:')\n",
    "print(f'  Training samples: {len(train_data_enhanced):,}')\n",
    "print(f'  Test samples: {len(test_data_enhanced):,}')\n",
    "print(f'  Tabular features: {len(feature_cols)}')\n",
    "print(f'  Image features (PCA): {n_components}')\n",
    "print(f'  Total features: {len(feature_cols) + n_components}')\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('✓ Ready for model training!')\n",
    "print('  → Run model_training.ipynb next')\n",
    "print('='*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
